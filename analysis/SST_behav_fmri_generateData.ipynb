{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SST (Spatial Stress Test) Behavioral Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is designed to extract the relevant nav data from log files. Info includes events of interest (orientation, task assignment, navigation, goal arrival, shocks), button presses (up, left, right keys down/up), as well as down-sampled (500ms rate) position (x,y coordinates), heading direction, and button box inputs (holding down up/left/right buttons).\n",
    "\n",
    "- This is just for the fMRI task, so onsets are determined (relative to scan trigger, and subtracting 8 s to allow for dropping of 4 TRs of data; `time_adj`). Crashes are dealt with by incrementing run numbers. Also deals with repeated \"ARRIVED\" flags (e.g., removes running into sub-goals, takes the first time point when arriving at goal). Prints out some flags/info from each subject's data file.\n",
    "\n",
    "- Log files were updated for crashes so that crashed environments not included; should we exclude these TRs from the data files? Similarly for one subj where env was re-run accidentally -- remove from the beginning of that run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0f5268aa0a58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmoss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'moss'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import moss\n",
    "from scipy import stats\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as op\n",
    "import re\n",
    "\n",
    "#widget ability\n",
    "import ipywidgets\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "from IPython.display import clear_output, display, HTML\n",
    "\n",
    "import glob\n",
    "\n",
    "# Gather project info & functions\n",
    "from sst_setup_project import *\n",
    "\n",
    "# for plotting\n",
    "sns.set(style='whitegrid', context='poster')\n",
    "%matplotlib inline\n",
    "\n",
    "# R for stats\n",
    "# %load_ext rpy2.ipython\n",
    "# %R require(lme4)\n",
    "# %R require(lmerTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_sec_reindex(df, rate='500L'):\n",
    "    '''Downsamples dataframe, assuming has column time in seconds, and then goes back to original index'''\n",
    "    \n",
    "    # Downsample\n",
    "    df['s'] = pd.to_datetime(df.time, unit='s') # convert time to pandas \"time\"\n",
    "    df = df.resample('500L', on='s').first() # take the first sample; this conserves non-numeric cols\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # reindex\n",
    "    df['index'] = df['index'].astype(int)\n",
    "    df = df.set_index('index')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up directories & exp-specific information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'op' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1efd40943117>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdirs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdirs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'basedir'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'~'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Documents\\MAP_RA\\Documents\\SSA\\SST-master'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdirs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'navdir'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'~'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Documents\\MAP_RA\\Documents\\SSA\\SST-master\\data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdirs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'analydir'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'basedir'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'analysis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdirs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'subj_info_file'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'navdir'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'subj_info.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'op' is not defined"
     ]
    }
   ],
   "source": [
    "dirs = dict()\n",
    "dirs['basedir'] = op.join(op.expanduser('~'), 'Documents\\MAP_RA\\Documents\\SSA\\SST-master')\n",
    "dirs['navdir'] = op.join(op.expanduser('~'), 'Documents\\MAP_RA\\Documents\\SSA\\SST-master\\data')\n",
    "dirs['analydir'] = op.join(dirs['basedir'], 'analysis')\n",
    "dirs['subj_info_file'] = op.join(dirs['navdir'], 'subj_info.csv')\n",
    "dirs['shortcut_file'] = op.join(dirs['navdir'],'shortcut_coords.csv')\n",
    "dirs['order_file'] = op.join(dirs['navdir'],'SST_env_order.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2\n"
     ]
    }
   ],
   "source": [
    "proj = gather_experiment_info(exp_name='SST', dirs=dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in subject information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "control    22\n",
       "stress     21\n",
       "Name: group, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_info = pd.read_csv(dirs['subj_info_file'])\n",
    "subj_info = subj_info[pd.isnull(subj_info.remove)]\n",
    "subj_info[['subid']] = subj_info.subid.astype(str)\n",
    "subj_info.group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shortcut_coords = pd.read_csv(dirs['shortcut_file'])\n",
    "\n",
    "trial_order = pd.read_csv(dirs['order_file'])\n",
    "trial_order[['subid']] = trial_order[['subid']].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in/concatenate data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only need to run this if first time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:86: FutureWarning: pd.groupby() is deprecated and will be removed Please use the Series.groupby() or DataFrame.groupby() methods\n",
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subid  run  type\n",
      "0    50    1     3\n",
      "**** 1 SCAN TRIGGERS! ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj d2 shape:(337068, 12)\n",
      "3\n",
      "3\n",
      "3.0 environments dont have 3 trials.\n",
      "0 shocks.\n",
      "subj data (downsampled) shape:(2367, 16)\n",
      "Group df shape: (2367, 16)\n",
      "_______________________________________\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame() # dataframe of subjs x envs\n",
    "test = True\n",
    "n_runs = 1\n",
    "\n",
    "test_types = ['habit', 'shortcut']\n",
    "\n",
    "# iterate through subjects\n",
    "# for subid in subj_info.subid:\n",
    "#for subid in subj_info.subid[:37]:\n",
    "for subid in ['50']:\n",
    "    print subid\n",
    "    \n",
    "    if test:\n",
    "        d2 = pd.DataFrame() # dataframe of test files for a subj\n",
    "        \n",
    "        crash_subject = False # set flag for whether crash subject (more than 12 runs)\n",
    "        crash_num = 0 \n",
    "\n",
    "        # iterate through environments\n",
    "        for run_num in range(1, n_runs+1):\n",
    "\n",
    "            # deal w/num -> str IDs\n",
    "            if int(subid) < 10:\n",
    "                sub_str = 'sst0'\n",
    "            else:\n",
    "                sub_str = 'sst'\n",
    "\n",
    "            # add test file\n",
    "            test_files = glob.glob(op.join(dirs['navdir'], sub_str + str(subid), \n",
    "                                           'run'+ str(run_num),\n",
    "                                           'session_*', 'log.txt'))\n",
    "\n",
    "            # get all files, including crashes where 2 files/run\n",
    "            # note that grouping files into same \"run\" if a crash to merge with env order; \n",
    "            # however, scan runs need to be incremented based on number of crashes\n",
    "            for i, test_file in enumerate(test_files):\n",
    "\n",
    "                if i > 0: \n",
    "                    print '***** something happened, '+str(i+1)+' files for run ' +str(run_num)+'! *****'\n",
    "                    crash_subject = True\n",
    "                    crash_num += 1\n",
    "                    print 'Crash #: ' + str(crash_num)\n",
    "\n",
    "                output = []\n",
    "                with open(test_file) as f:\n",
    "                    data = f.readlines()\n",
    "\n",
    "                    for line in data:\n",
    "                        columns = re.split('\\t|\\r|\\n', line)\n",
    "                        output.append(columns)\n",
    "\n",
    "                d1 = pd.DataFrame(output, columns = ['time', 'c2', 'command', \n",
    "                                                     'c3', 'c4', 'c5', 'c6', 'c7'])#, 'c8'])\n",
    "\n",
    "                # include subid and env\n",
    "                d1['subid'] = subid\n",
    "                d1['run'] = run_num # matching w/env order file\n",
    "                d1['scan'] = run_num + crash_num # matching w/fMRI data\n",
    "\n",
    "                if run_num < 5: # TIB 01/27 WARNING this is hardcoded - assumes first 4 runs are \"familiar\" - change depending on truth\n",
    "                    d1['type'] = 'habit'\n",
    "                else:\n",
    "                    d1['type'] = 'shortcut'\n",
    "\n",
    "                # force time to in seconds, relative to beginning of session\n",
    "                d1.time = d1.time.astype('int64')/1000 # TIB 01/27 CHANGED to int64 from dropbox\n",
    "\n",
    "                if (run_num == 1) & (i == 0):\n",
    "                    session_start = d1.time.min()\n",
    "                d1.time = d1.time - session_start\n",
    "\n",
    "                # calculate time relative to scan start - 8 # adjust for tossed volumes (4 TRs, 8 s (2s TR))\n",
    "                run_scan_trigger = d1.loc[d1.command == 'SCAN', 'time'].values[0]\n",
    "                d1['time_adj'] = d1.time - run_scan_trigger - 8\n",
    "\n",
    "                # Append to subj's dataframe\n",
    "                d2 = d2.append(d1, ignore_index=True)\n",
    "\n",
    "        d2 = d2.loc[d2.command.isin(['VROBJECT_POS', 'VROBJECT_HEADING', 'INPUT_EVENT',\n",
    "                                     'KEYBOARD_UP', 'KEYBOARD_DOWN',\n",
    "                                     'ORIENT', 'ARRIVED', 'ASSIGNED', 'NAVIGATE', \n",
    "                                     'SCAN', 'SHOCK'])]\n",
    "        d2.drop(['c2', 'c5', 'c6', 'c7'], axis=1,inplace=True)#, 'c8'], axis=1, inplace=True) #unneeded cols\n",
    "\n",
    "        # Any runs without 3 trials?\n",
    "        counts = pd.groupby(d2.loc[d2.command == \"ORIENT\"], by=['subid', 'run']).count().reset_index()\n",
    "        print counts[['subid', 'run', 'type']]\n",
    "        if counts[counts.command != 3].shape[0] > 0: print 'Don''t have 3 trials for a run!'\n",
    "\n",
    "        # Get orient onsets, for trial parsing\n",
    "        d2.sort_values(by='time', inplace=True) # make sure sorted by time! this can be weird w/crashes\n",
    "        orient_onsets = d2.loc[d2.command == \"ORIENT\"]\n",
    "        orient_onsets['trial'] = 0 # init trial number\n",
    "\n",
    "        # figure out time relative to scan trigger\n",
    "        scan_triggers = d2.loc[d2.command == 'SCAN']\n",
    "        if scan_triggers.shape[0] != 12: print '**** '+str(scan_triggers.shape[0])+' SCAN TRIGGERS! ****'\n",
    "\n",
    "        # assign trial numbers\n",
    "        for counter, ind in enumerate(orient_onsets.index):\n",
    "            if counter == 0: # first trial\n",
    "                first_ind = ind\n",
    "                orient_onsets.loc[ind, 'trial'] = 1\n",
    "                prev_ind = ind\n",
    "            else:\n",
    "                if orient_onsets.loc[ind, 'run'] == orient_onsets.loc[prev_ind, 'run']:\n",
    "                    orient_onsets.loc[ind, 'trial'] = orient_onsets.loc[prev_ind, 'trial'] + 1\n",
    "                    prev_ind = ind\n",
    "                else:\n",
    "                    orient_onsets.loc[ind, 'trial'] = 1\n",
    "                    prev_ind = ind\n",
    "\n",
    "        orient_onsets = orient_onsets.reset_index().merge(trial_order)\n",
    "\n",
    "        d2['env'] = np.nan\n",
    "        d2['rep'] = np.nan\n",
    "        d2['trial'] = np.nan\n",
    "\n",
    "        for i in orient_onsets.index:\n",
    "            index_val = orient_onsets.loc[i, 'index']\n",
    "            d2.loc[index_val, 'env'] = 'env' + orient_onsets.loc[i, 'env'].astype(str)\n",
    "            d2.loc[index_val, 'rep'] = orient_onsets.loc[i, 'rep']\n",
    "            d2.loc[index_val, 'trial'] = orient_onsets.loc[i, 'trial']\n",
    "\n",
    "        d2.env.fillna(method='ffill', inplace=True)\n",
    "        d2.rep.fillna(method='ffill', inplace=True)\n",
    "        d2.trial.fillna(method='ffill', inplace=True)\n",
    "\n",
    "        d2 = d2.loc[~d2.env.isnull()]\n",
    "\n",
    "        print 'subj d2 shape:' + str(d2.shape)\n",
    "        print len('env' + orient_onsets.env.astype(str))\n",
    "        print len(d2.loc[orient_onsets['index'], 'env'])\n",
    "\n",
    "        # Experiment trial-segment onsets\n",
    "        ####################################\n",
    "        onset_times = d2.loc[d2.command.isin(['ORIENT', 'ASSIGNED', 'NAVIGATE', 'SHOCK'])]\n",
    "        \n",
    "        # prune \"ARRIVED\" if not to a target (eg if run into sub-goal)\n",
    "        targets = ['ZZZ', 'Jim_Parsons', 'Beyonce', 'Paul_McCartney', \n",
    "                   'Natalie_Portman', 'Benedict_Cumberbatch',\n",
    "                   'Taylor_Swift', 'Katy_Perry', 'Johnny_Depp', \n",
    "                   'Zooey_Deschanel', 'George_Clooney', 'Mark_Zuckerberg','Emma_Watson']\n",
    "        \n",
    "        arrived_times = d2.loc[(d2.command == 'ARRIVED') & (d2.c3.isin(targets))]\n",
    "        \n",
    "        # Only use first \"ARRIVED\" for a target (some generate a bunch)\n",
    "        onset_times = onset_times.append(arrived_times.loc[arrived_times.groupby(['run', 'trial'])[\"time\"].idxmin()])\n",
    "             \n",
    "        # Figure out if each critical command doesn't have 3 trials\n",
    "        critical_commands = ['ORIENT', 'ASSIGNED', 'NAVIGATE', 'ARRIVED']\n",
    "        n_env_not3trials = sum(onset_times.loc[onset_times.command.isin(critical_commands)].groupby(['env', 'command']).count().trial != 3)\n",
    "        if n_env_not3trials > 0: \n",
    "            print str(float(n_env_not3trials)/len(critical_commands)) + ' environments don''t have 3 trials.'\n",
    "#             print onset_times.groupby(['env', 'command']).count()\n",
    "            \n",
    "        # Number of shocks\n",
    "        print str(d2.loc[d2.command.isin(['SHOCK'])].shape[0]) + ' shocks.'\n",
    "\n",
    "        # keyboard events\n",
    "        keyboard_events = d2.loc[d2.command.isin(['KEYBOARD_DOWN', 'KEYBOARD_UP'])]\n",
    "\n",
    "        # Get 2D position in space\n",
    "        #######################################\n",
    "        dp = d2.loc[d2.command == 'VROBJECT_POS'].reset_index()\n",
    "        coordinates = pd.DataFrame(dp.c4.str.split('Point3|, |\\(|\\)').tolist())[[2, 3, 4]]\n",
    "        coordinates.rename(columns={2: 'x', 3: 'y', 4: 'z'}, inplace=True)\n",
    "\n",
    "        dp = dp.join(coordinates)\n",
    "        dp[['x', 'y', 'z']] = dp[['x', 'y', 'z']].astype(float)\n",
    "\n",
    "        dp = downsample_sec_reindex(dp, rate='500L')\n",
    "        dp = dp.loc[dp.c3 == 'PandaEPL_avatar'] # remove positions that aren't actually navigator\n",
    "\n",
    "        # Get heading direction\n",
    "        #######################################\n",
    "        dh = d2.loc[d2.command == 'VROBJECT_HEADING'].reset_index()\n",
    "        dh = downsample_sec_reindex(dh, rate='500L')\n",
    "\n",
    "        # Get input events (holding down button)\n",
    "        di = d2.loc[d2.command == 'INPUT_EVENT'].reset_index()\n",
    "        di = downsample_sec_reindex(di, rate='500L')\n",
    "\n",
    "        # Re-combine dataframes\n",
    "        data = pd.concat([onset_times, keyboard_events, dp, dh, di]).sort_index()\n",
    "        print 'subj data (downsampled) shape:' + str(data.shape)\n",
    "\n",
    "        # Append to group data\n",
    "        df = df.append(data, ignore_index=True)\n",
    "        print 'Group df shape: ' + str(df.shape)\n",
    "        print '_______________________________________'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prune down the data (>13 million rows beforehand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "``/Volumes/group/awagner/sgagnon/SST/nav_data`` does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-83f333b9d248>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/Volumes/group/awagner/sgagnon/SST/nav_data/group_fmri_onsets.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'df'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fixed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36mto_hdf\u001b[1;34m(self, path_or_buf, key, **kwargs)\u001b[0m\n\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpytables\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpytables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1301\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_msgpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\pytables.pyc\u001b[0m in \u001b[0;36mto_hdf\u001b[1;34m(path_or_buf, key, value, mode, complevel, complib, append, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         with HDFStore(path_or_buf, mode=mode, complevel=complevel,\n\u001b[1;32m--> 279\u001b[1;33m                       complib=complib) as store:\n\u001b[0m\u001b[0;32m    280\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\pytables.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fletcher32\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfletcher32\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\pytables.pyc\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIOError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'can not be written'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\tables\\file.py\u001b[0m in \u001b[0;36mopen_file\u001b[1;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[1;31m# Finally, create the File instance, and return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_uep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\tables\\file.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m         \u001b[1;31m# Now, it is time to initialize the File extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_g_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m         \u001b[1;31m# Check filters and set PyTables format version for new files.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtables\\hdf5extension.pyx\u001b[0m in \u001b[0;36mtables.hdf5extension.File._g_new\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\tables\\utils.py\u001b[0m in \u001b[0;36mcheck_file_access\u001b[1;34m(filename, mode)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0mparentname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparentname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mF_OK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"``%s`` does not exist\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mparentname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparentname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"``%s`` is not a directory\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mparentname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: ``/Volumes/group/awagner/sgagnon/SST/nav_data`` does not exist"
     ]
    }
   ],
   "source": [
    "filename = '/Volumes/group/awagner/sgagnon/SST/nav_data/group_fmri_onsets.h5'\n",
    "df.to_hdf(filename, 'df', mode='w', format='fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '/Volumes/group/awagner/sgagnon/SST/nav_data/group_fmri_onsets.h5'\n",
    "df_in = pd.read_hdf(filename, 'df')\n",
    "df_in.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Subject 11 is missing evns 8 and 9 (run 2 of habit)\n",
    "- Subj 14 is missing last trial of run 3 (habit); (env9) check that other 2 events are ok\n",
    "- Subj 20 is missing 2nd rep through envs 10-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_in = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efac8b902e6844c090a78948c7934b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_sub(subj, env, test_trial, rep):\n",
    "    plot_paths(env=env, subj=subj, \n",
    "               dp=df_in.loc[(df_in['type'] == test_trial) &\n",
    "                            (df_in.rep == rep)], \n",
    "               proj=proj, dirs=dirs)\n",
    "    \n",
    "subj_opts = ipywidgets.Select(options=list(df_in.subid.unique()))\n",
    "env_opts = ipywidgets.ToggleButtons(options=list(np.sort(df_in.env.unique())))\n",
    "test_opts = ipywidgets.ToggleButtons(options=list(['habit', 'shortcut']))\n",
    "rep_opts = ipywidgets.IntSlider(min=1, max=2)\n",
    "\n",
    "w = ipywidgets.interact(plot_sub, \n",
    "                        subj=subj_opts, \n",
    "                        env=env_opts, \n",
    "                        test_trial=test_opts, \n",
    "                        rep=rep_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20: has 3 reps of envs 4-6, and doesn't have 2nd rep of envs 10-12\n",
    "- 40 (habit, env3): loops around too many times, and wrong env? [looks like ran through envs 4,5,3, crashed on 3, and then restarted to run through 5 and 3 again. Removed run 3 from first log file, and run 5 from 2nd log file (but keep beginning of log file to have right number of cols) -- kept SCAN too, to determine onset times]\n",
    "- 38 \n",
    "    - (shortcut 1, env8, 9): wrong map? [appears to be env7 run crashed partway through, then restarted and ran again -- moved the initial env7 to main sst38 folder, append run_5 to start]\n",
    "    - (shortcut 1, env7): didn't end?\n",
    "    - (habit, env11, env6): wrong env? [town 7 was repeated twice, so moved first iteration log file/dir out into main sst38 folder, append run_4 to start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
